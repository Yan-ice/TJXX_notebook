# EM 算法（Expectation-Maximization Algorithm）

## 1. 定义
EM 算法是 **Expectation-Maximization（期望最大化）** 的简称，是一种用于含有隐藏变量（latent variables）的概率模型中的参数估计算法。它是一种迭代优化算法，通过交替进行期望步骤（E 步骤）和最大化步骤（M 步骤），逐步逼近模型参数的最大似然估计值。

## 2. 适用场景
EM 算法通常用于存在未观测数据（隐藏变量）的情形，例如：
- **混合模型**：如高斯混合模型（Gaussian Mixture Models, GMM），其中观测数据是多个高斯分布的混合，但无法直接观测到每个样本来自哪个高斯分布。
- **缺失数据**：如数据集中某些特征是缺失的，需要估计这些缺失部分。
- **隐马尔可夫模型（HMM）**：HMM 模型中，观测序列背后的隐藏状态是不可见的。

## 3. 最大似然估计
假设我们有观测数据集 \( X = \{x_1, x_2, \dots, x_n\} \)，以及隐藏变量 \( Z = \{z_1, z_2, \dots, z_n\} \)，EM 算法的目标是通过最大化 **边际似然函数** 来估计模型参数 \( \theta \)：
\[
L(\theta) = P(X | \theta) = \sum_{Z} P(X, Z | \theta)
\]
由于 \( Z \) 是隐藏的，直接最大化 \( P(X | \theta) \) 可能非常困难，因此 EM 算法通过迭代地优化以下两个步骤来估计参数。

---

## 4. EM 算法步骤

### 4.1 E 步骤（Expectation Step）
在 E 步骤中，计算隐藏变量的 **期望值**，即给定当前参数估计 \( \theta^{(t)} \) 和观测数据 \( X \)，估计每个隐藏变量的后验概率：
\[
Q(\theta | \theta^{(t)}) = E_{Z|X, \theta^{(t)}} \left[ \log P(X, Z | \theta) \right]
\]
这个步骤的核心是计算出在当前参数 \( \theta^{(t)} \) 下，隐藏变量 \( Z \) 的分布，即 \( P(Z | X, \theta^{(t)}) \)。

### 4.2 M 步骤（Maximization Step）
在 M 步骤中，最大化 E 步骤中计算得到的期望函数 \( Q(\theta | \theta^{(t)}) \)，从而更新模型参数 \( \theta \)：
\[
\theta^{(t+1)} = \arg \max_{\theta} Q(\theta | \theta^{(t)})
\]
这个步骤的核心是找到使得对数似然期望值最大的参数 \( \theta \)，即更新模型的参数。

### 4.3 迭代过程
- E 步：给定当前的参数估计 \( \theta^{(t)} \)，计算隐藏变量的后验概率。
- M 步：最大化期望的对数似然值，更新参数 \( \theta^{(t+1)} \)。
- 交替进行 E 步和 M 步，直到收敛，即 \( \theta^{(t+1)} \) 和 \( \theta^{(t)} \) 差异很小，或达到某个预设的收敛条件。

---

## 5. 直观理解

### 5.1 隐藏变量与观测数据
在很多实际问题中，观测数据 \( X \) 并不能直接提供完整的模型信息，部分信息是 "隐藏的"。EM 算法通过在每一轮迭代中，用当前的参数估计推断这些隐藏变量的期望值，然后再使用这些估计值来更新参数。

### 5.2 类比
EM 算法可以类比为猜测-修正过程：
- **E 步**：猜测（推断）隐藏变量的值；
- **M 步**：根据推断出的隐藏变量，修正（更新）模型的参数。

---

## 6. 应用场景

### 6.1 高斯混合模型（Gaussian Mixture Models, GMM）
在高斯混合模型中，观测数据可以看作是多个不同高斯分布的混合，但样本的归属类别是隐藏的。EM 算法通过迭代地估计样本来自哪个分布（E 步）并更新分布的参数（M 步），逐步逼近最大似然估计。

### 6.2 隐马尔可夫模型（Hidden Markov Model, HMM）
在 HMM 中，观测数据的生成依赖于隐藏的马尔可夫状态序列。EM 算法（具体实现为 Baum-Welch 算法）可以用于估计 HMM 的状态转移矩阵和观测概率。

---

## 7. 收敛性
EM 算法具有以下特性：
- **单调性**：每次迭代后，似然函数值不会减小（即 E 步和 M 步会使得对数似然值增加或保持不变）。
- **局部最优**：EM 算法可能收敛到局部最优解，因此初始参数选择较为关键。

---

## 8. 优缺点

### 优点
- **处理隐藏变量问题**：EM 算法能够有效地处理存在隐藏变量的模型。
- **迭代更新**：算法简单，易于实现，且每次迭代都能提高对数似然值。

### 缺点
- **收敛到局部最优**：由于可能陷入局部最优解，EM 算法对初始值敏感。
- **收敛速度慢**：在某些情况下，EM 算法的收敛速度较慢，尤其是接近收敛点时。

---

## 9. 总结
EM 算法是一种处理含有隐藏变量的模型中参数估计的有力工具。它通过 E 步和 M 步的交替迭代，逐步逼近模型参数的最大似然估计值。尽管可能陷入局部最优解，但其简单的迭代框架使得 EM 算法在许多应用中非常有效，特别是混合模型和隐马尔可夫模型等场景。
